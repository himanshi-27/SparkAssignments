{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-X8O1gLuBuSY"
   },
   "source": [
    "#IS6493 - Data Science & Big Data\n",
    "# Final Report\n",
    "# Clickstream Analysis for Outbrain \n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "*Submitted by: Ann-Kathrin Breuning(u1158200), Srivatsa Gangadhara(u1087996), Evelyn Mietzner(u0573308), Himanshi Sharma(u1168592)*\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fV6LUW35k3n4"
   },
   "source": [
    "#Introduction\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "##** Background**\n",
    "Outbrain is an online advertiser that connects businesses with their target audience by presenting the businesses’ ads on a third-party website. Outbrain is charging its clients on a Pay-Per-Click basis; about half of the revenue goes to the third-party website that  presented the ad. To only present the most relevant content to the third-party website visitor, Outbrain uses a recommendation algorithm. This project will try to help Outbrain to improve this algorithm to present more relevant content to individuals.\n",
    "\n",
    "## Goal\n",
    "\n",
    "Analysis of clickstream data using web analytics procedures serves as a useful tool in the enhancement of a\n",
    "B2B website by investigating how visitors move through the website conversion process. Determining which\n",
    "content, the user might click can earn huge revenues for an Ad aggregator like Outbrain. On inserting a relevant\n",
    "content to the slot, and these contents generates many clicks in turn more revenue to the company. \n",
    "\n",
    "## ** Business Questions**\n",
    "\n",
    "- Most revenue generating content category?\n",
    "- What are the most popular ads?\n",
    "- What factors influence click-through-rate?\n",
    "- Where are your visitors geographically located?\n",
    "- Overall Goal: What pieces of content are more likely to be clicked on?\n",
    "\n",
    "## Value proposition and Benefits\n",
    "Big data analytics helps organizations harness their data and use it to identify new opportunities. That, in\n",
    "turn, leads to smarter business moves, more efficient operations, higher profits and happier customers.\n",
    "This can add value in the following ways:\n",
    "1. Cost reduction - Big data technologies such as Hadoop and cloud-based analytics bring significant cost\n",
    "advantages when it comes to storing large amounts of data and they can identify more efficient ways of\n",
    "doing business\n",
    "\n",
    "2. Faster, better decision making - With the ability to analyze new sources of data, businesses can analyze\n",
    "information immediately – and make decisions based on what they’ve learned\n",
    "\n",
    "3. New products and services - With the ability to gauge customer needs and satisfaction through analytics\n",
    "comes the power to give customers what they need and want without them asking for it\n",
    "\n",
    "4. For our project, the most beneficial findings include:\n",
    "    - Highest number of visitors to a content\n",
    "    - Popular content category based on clicks\n",
    "    - Popular content category based on geographical area\n",
    "    \n",
    "The risk of not achieving this would lead to fail in creating click conversions and hence decreased revenues\n",
    "\n",
    "## Data Mining Tasks\n",
    "Our business focus is determining what ads work and what does not, as this forms the center for many\n",
    "advertising firms which are striving to find the best revenue generating ads. In order to categorizing ads in\n",
    "profitable and non-profitable classes we plan to first performed exploratory data analysis to understand the\n",
    "underlying relationships between a website, campaign and set of recommendations Outbrain is providing.\n",
    "\n",
    "\n",
    "![Graph showing the ads distribution in train data](https://lh4.googleusercontent.com/6O3pYphjiHoujGGcf8ahGqKYU9JNv4tbuiI7hLGmxcoNJJyjfTXcMYkaM3hcyG5qKiVwaiNpBsJg3cirx6Po=w1280-h694)\n",
    "\n",
    "The graph above shows the distribution of ads in displays, and we can see that the most of the displays (~30%) have 4 ads.\n",
    "\n",
    "The graph below shows the clicking distribution of ads in training set.\n",
    "\n",
    "![Graph showing if ads were clicked or not](https://lh5.googleusercontent.com/88yePL8qh5MnfWjvu6swPdXVNq3Q1cWqL9nIbP-h_rsnCwFwQz-5WJqLF4EuhUJcrnc3ych-PyoRS473Xieg=w1280-h694)\n",
    "\n",
    " \n",
    " The graph above shows the clicking percentage of ads in display. \n",
    " \n",
    "\n",
    "![Graph showing the clicking percentage of ads in ad groups](https://lh3.googleusercontent.com/w7gCFZY3Z1NEcDMf6NuAhTMN1jUQ3jeXUHipPiTM6HCxXsUgIXLVqRfczurOu1HfpEVVn43xwIikhQK6mVOk=w1280-h694)\n",
    "\n",
    "Second, using the explained relationships, and clicked (1 for if ad is clicked and 0 otherwise) as target\n",
    "variable we can use classifications techniques like Logistic Regression, Random Forest etc. to find the\n",
    "likelihood of a person clicking or not clicking a recommended ad. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZdA91cXwndwH"
   },
   "source": [
    "#Data\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "##Dataset\n",
    "The data set for the project is from a data challenge by Outbrain on Kaggle.com\n",
    "[lKaggle Outbrain](https://www.kaggle.com/c/outbrain-click-prediction).\n",
    "\n",
    "## Metadata\n",
    "The dataset for the competition is comprised of a sample from June 14, 2016 to June 28, 2016 of users’ page\n",
    "views and clicks collected from various publisher sites in the US. Following are the common fields among the\n",
    "various files of the competition data:\n",
    "- Unique id(uuid): Each user is represented by these unique id.\n",
    "- Document id(document_id): It represents the document/webpage a user visit.\n",
    "- Ads id(ads_id): Represents the set of ads that are displayed on the document.\n",
    "- Campaign id(compaign_id): Represents the campaign of a particular ad on the document.\n",
    "- Advertiser id(advertiser_id): It represents the advertiser running the campaigns.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J42Wv5lNBuSl"
   },
   "source": [
    "#** Prepared Data and Data Mining Results**\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "## Data Preperation\n",
    "\n",
    "Before we can start the analysis we have to prepare our data. The following section is dedicated to that. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "7gVGAPyLlDyo"
   },
   "outputs": [],
   "source": [
    "# Packages needed for data preperation (some data exploration)\n",
    "import csv\n",
    "from pyspark.sql.functions import col, count, countDistinct\n",
    "\n",
    "from pyspark.ml.feature import RFormula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "qriM6K_ulVTS"
   },
   "outputs": [],
   "source": [
    "clicks_train = spark.read.csv(\"clicks_train.csv\", header = True, inferSchema=\"true\")\n",
    "clicks_train.printSchema()\n",
    "clicks_train.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "lAeEnjCMleCn"
   },
   "outputs": [],
   "source": [
    "#decrease size\n",
    "clicks_train = clicks_train.where(col(\"ad_id\")<500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "xe7FzvfAlfDN"
   },
   "outputs": [],
   "source": [
    "events = spark.read.csv(\"events.csv\", header = True, inferSchema = \"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "q3doIb3NlkQn"
   },
   "outputs": [],
   "source": [
    "## Join by display_id\n",
    "# Join expression\n",
    "joinExpression = clicks_train[\"display_id\"] == events[\"display_id\"]\n",
    "# Join type\n",
    "joinType = \"inner\"\n",
    "# Join command\n",
    "data = clicks_train.join(events, joinExpression, joinType)\n",
    "# Drop redundant columns\n",
    "data = data.drop(events[\"display_id\"])\n",
    "data.printSchema()\n",
    "data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "VSkNVmkilucF"
   },
   "outputs": [],
   "source": [
    "promoted_content = spark.read.csv(\"promoted_content.csv\", header = True, inferSchema = \"true\")\n",
    "promoted_content.printSchema()\n",
    "promoted_content.show(5)\n",
    "promoted_content.select(count(\"ad_id\").alias(\"Number of ads\"), \n",
    "                       count(\"display_id\").alias(\"Number of displays\")\n",
    "                       count(\"compaign_id\").alias(\"Number of campaigns\"), \n",
    "                       count(\"advertiser_id\").alias(\"Number of advertiser\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "NQHz7VXUa2YT"
   },
   "outputs": [],
   "source": [
    "clicks_test = spark.read.csv(\"clicks_test.csv\", header = True, inferSchema = \"true\")\n",
    "clicks_test.printSchema()\n",
    "clicks_test.show(5)\n",
    "clicks_test.select(count(\"ad_id\").alias(\"Number of ads\"), \n",
    "                   count(\"display_id\").alias(\"Number of displays\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "JoWsBe1vlwoE"
   },
   "outputs": [],
   "source": [
    "## Join by document_id\n",
    "# Join expression\n",
    "joinExpression = data[\"document_id\"] == documents_topics[\"document_id\"]\n",
    "# Join type\n",
    "joinType = \"inner\"\n",
    "# Join command\n",
    "data = data.join(documents_topics, joinExpression, joinType)\n",
    "# Drop redundant columns\n",
    "data = data.drop(documents_topics[\"document_id\"])\n",
    "data.printSchema()\n",
    "data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "VZzAqbWEWzzx"
   },
   "outputs": [],
   "source": [
    "data.select(countDistinct(\"ad_id\")).show()                  #many different categories so we chose not to\n",
    "data.select(countDistinct(\"geo_location\")).show()           #show the distribution because of lack of space\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Z1ndUpjNZkHf"
   },
   "outputs": [],
   "source": [
    "#distribution\n",
    "data.groupBy(\"clicked\").count().show()\n",
    "data.groupBy(\"platform\").count().show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dX2tTwnqBuSs"
   },
   "source": [
    "## Data Mining methods selected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ikdxUJ97XBeK"
   },
   "source": [
    "1. Data Mining Method: Simple Aggregation, Logistic Regression, Cost Sensitive Analysis, Random Forest Classification\n",
    "These methods were used because we wanted to classify our target variable \"clicked\" in two class - 0: not clicked and 1: clicked.\n",
    "\n",
    "2. Goal: Predict future clicks\n",
    "      + We are trying to follow the Kaggle instructions and use our Random Forest Classification (and Simple Aggregation) on training data (formed with joining clicks_train and promoted_content) to predict future clicks on the provided test dataset (formed with joining click_test and promoted_content)\n",
    "      + The logistic model and cost sensitive model don't use the given test set at all but rather uses a join of clicks_train, events, and document_topics tables to foresee future clicks based on a broader range of independent variables. The given test set only works with display_id and ad_id."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9ukL1wIADKOt"
   },
   "source": [
    "## Data Mining Models\n",
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "wi1qQUCW86u1"
   },
   "outputs": [],
   "source": [
    "# original selection\n",
    "data1 = data.select('clicked', 'ad_id', 'geo_location', 'platform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "LSzTvSTXFkLP"
   },
   "outputs": [],
   "source": [
    "formula = RFormula(\n",
    "    formula=\"clicked ~ . ad_id:geo_location\",\n",
    "    featuresCol=\"features\",\n",
    "    labelCol=\"label\")\n",
    "\n",
    "df1 = formula.fit(data1).transform(data1)\n",
    "df1.show(5)\n",
    "train3 test3 = df1.select('label', 'features').randomSplit([0.7, 0.3], seed=2018)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hh1YN7ieDs5S"
   },
   "source": [
    "### Cost Sensitve Model\n",
    "The data is very unbalanced in terms of the positive class (click) versus the negative class (no click). In other words, the data contains far more cases in which the dependent variable *clicked* equals 0, meaning no click, than clicks. This has been an issue for classification models for quite some time. Cost sensitive models offer a solution to the problem by associating a cost with a false prediction - in the case of Outbrain the false positive (predicting a click that actually isn't one) and the false negative (predicting no click although it is a click) are linked to a cost. A model will be more meek in making a decision based on the value of the cost. \n",
    " \n",
    "Pyspark currently doesn't support cost sensitive models. Therefore, the following code was written in R and will only be executable by R."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "cellView": "code",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "GV0fzGAmHwmL"
   },
   "outputs": [],
   "source": [
    "#Cost Sensitive Model\n",
    "library(RWeka)\n",
    "data <- read.csv(\"data.csv\")           #data is the join of clicks, events, and document_topic above\n",
    "str(data)\n",
    "data$clicked <- factor(data$clicked)\n",
    "data$ad_id <- factor(data$ad_id)\n",
    "data$platform <- factor(data$platform)\n",
    "data <- data[,-c(1,7)]\n",
    "data1 <- data[,c(2,3,6,7)]\n",
    "\n",
    "\n",
    "# cost matrix 1\n",
    "\n",
    "# Create a cost matrix \n",
    "matrix_dimensions <- list(c(\"True No-Click\", \"True Click\"), c(\"Predicted No-Click\", \"Predicted Click\"))\n",
    "\n",
    "costMatrix2 <- matrix(c(0,3,1,0),nrow=2,dimnames = matrix_dimensions)\n",
    "\n",
    "costMatrix2\n",
    "\n",
    "#  Configure the model using this cost matrix \n",
    "j48_cs_model2 <- CostSensitiveClassifier(clicked ~ ., data=data1,control=Weka_control('cost-matrix'=costMatrix2,\n",
    "                                                                                      W=\"weka.classifiers.trees.J48\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WW0QlESooMgz"
   },
   "source": [
    "## Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L0PFHgPDoQZf"
   },
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "n1znWkLWop0_"
   },
   "outputs": [],
   "source": [
    "# Define a function to generate a classification metrics\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "\n",
    "# Binary Classification\n",
    "def B_Classifier_evaluator (predictions):\n",
    "    predictionAndLabels =predictions.select(\"prediction\", \"label\").rdd\n",
    "    metrics = MulticlassMetrics(predictionAndLabels)\n",
    "    print(\"Precision(no):\", round(metrics.precision(0.0),3))\n",
    "    print(\"Recall(no):\", round(metrics.recall(0.0),3))\n",
    "    print(\"F-Score(no):\", round(metrics.fMeasure(0.0, beta=1.0),3))\n",
    "    print(\"Precision(yes):\", round(metrics.precision(1.0),3))\n",
    "    print(\"Recall(yes):\", round(metrics.recall(1.0),3))\n",
    "    print(\"F-Score(yes):\", round(metrics.fMeasure(1.0, beta=1.0),3))\n",
    "    print(\"Accuracy:\", round(metrics.accuracy,3))   \n",
    "    \n",
    "# logistic regression with interaction\n",
    "lr = LogisticRegression(labelCol = 'label', featuresCol = 'features')\n",
    "\n",
    "# training the model\n",
    "fittedLR = lr.fit(train3)\n",
    "\n",
    "# applying the model to the test set\n",
    "lr_test_results = fittedLR.transform(test3)\n",
    "\n",
    "# evaluating the models performance\n",
    "B_Classifier_evaluator(lr_test_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vyDa13jzkjV7"
   },
   "source": [
    "### Cost Sensitive Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "O1zC7u3Zkm3Z"
   },
   "outputs": [],
   "source": [
    "# Build and evaluate cost-sensitive models based on the configuration above via 10-fold cross validation using evaluate_Weka_classifier\n",
    "eval_j48_cs2 <- evaluate_Weka_classifier(j48_cs_model2,data1,numFolds = 10, complexity = FALSE,seed = 1, class = TRUE)\n",
    "\n",
    "eval_j48_cs2\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xB00DNRrjska"
   },
   "source": [
    "###Code For Simple Aggregation Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "otfmTKXTjxOu"
   },
   "outputs": [],
   "source": [
    "#loading the modules\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "4WBFvYgdjzRj"
   },
   "outputs": [],
   "source": [
    "## defining the data types\n",
    "dtypes = {'ad_id': np.float32, 'clicked': np.int8}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Jzj-AP9Lj2FY"
   },
   "outputs": [],
   "source": [
    "# loading train data\n",
    "train = pd.read_csv(\"clicks_train.csv\", usecols=['ad_id','clicked'], dtype=dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "nSXJwiEhj3ne"
   },
   "outputs": [],
   "source": [
    "# calculating likelihood as \n",
    "likelihood = train.groupby('ad_id').clicked.agg(['count','sum','mean']).reset_index()\n",
    "mean = train.clicked.mean()\n",
    "del train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "wJ7Db1Hnj50l"
   },
   "outputs": [],
   "source": [
    "likelihood['likelihood'] = (likelihood['sum'] + 12*mean) / (12 + likelihood['count'])\n",
    "test = pd.read_csv(\"clicks_test.csv\")\n",
    "test = test.merge(likelihood, how='left')\n",
    "test.likelihood.fillna(mean, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "xuTKIlz6j7Ng"
   },
   "outputs": [],
   "source": [
    "test.sort_values(['display_id','likelihood'], inplace=True, ascending=False)\n",
    "subm = test.groupby('display_id').ad_id.apply(lambda x: \" \".join(map(str,x))).reset_index()\n",
    "subm.to_csv(\"simple_submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-HEGmrhV-fyb"
   },
   "source": [
    "### Code For Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "QPvfrP-r-k4_"
   },
   "outputs": [],
   "source": [
    "# baseline logistic regression on original selection\n",
    "lr = LogisticRegression(labelCol = 'label', featuresCol = 'features')\n",
    "\n",
    "# training the model\n",
    "base_fittedLR = lr.fit(train1)\n",
    "\n",
    "# applying the model to the test set\n",
    "base_lr_test_results = base_fittedLR.transform(test1)\n",
    "\n",
    "# evaluating the models performance\n",
    "B_Classifier_evaluator(base_lr_test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "M3gc8C9c-lCH"
   },
   "outputs": [],
   "source": [
    "# baseline logistic regression on final selection (same performance as original selection)\n",
    "lr = LogisticRegression(labelCol = 'label', featuresCol = 'features')\n",
    "\n",
    "# training the model\n",
    "base_fittedLR = lr.fit(train2)\n",
    "\n",
    "# applying the model to the test set\n",
    "base_lr_test_results = base_fittedLR.transform(test2)\n",
    "\n",
    "# evaluating the models performance\n",
    "B_Classifier_evaluator(base_lr_test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "ZwCvdqIM-lNA"
   },
   "outputs": [],
   "source": [
    "# logistic regression with interaction term\n",
    "lr = LogisticRegression(labelCol = 'label', featuresCol = 'features')\n",
    "\n",
    "# training the model\n",
    "model1_fittedLR = lr.fit(train3)\n",
    "\n",
    "# applying the model to the test set\n",
    "model1_lr_test_results = model1_fittedLR.transform(test3)\n",
    "\n",
    "# evaluating the models performance\n",
    "B_Classifier_evaluator(model1_lr_test_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "lxFkfXHsNMrC"
   },
   "outputs": [],
   "source": [
    "# logistic regression with interaction term and parameters different than defauls\n",
    "lr = LogisticRegression(labelCol = 'label', featuresCol = 'features', maxIter=10, regParam=0.5, elasticNetParam=0.5)\n",
    "\n",
    "# training the model\n",
    "model2_fittedLR = lr.fit(train3)\n",
    "\n",
    "# applying the model to the test set\n",
    "model2_lr_test_results = model2_fittedLR.transform(test3)\n",
    "\n",
    "# evaluating the models performance\n",
    "B_Classifier_evaluator(model2_lr_test_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wo9_PhN2OVgM"
   },
   "source": [
    "We changed the parameters to many different values but all of them performed worse than the default. The above model is just one example and stands for all the models we tested. It is also one of the worst performers. It doesn't predict any clicks at all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "UbxArCOH-laY"
   },
   "outputs": [],
   "source": [
    "# baseline logistic regression modeled and evaluated on similar format as the competition's train and test set\n",
    "lr = LogisticRegression(labelCol = 'label', featuresCol = 'features')\n",
    "\n",
    "# training the model\n",
    "base_fittedLR = lr.fit(train4)\n",
    "\n",
    "# applying the model to the test set\n",
    "base_lr_test_results = base_fittedLR.transform(test4)\n",
    "\n",
    "# evaluating the models performance\n",
    "B_Classifier_evaluator(base_lr_test_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dSHFg0NWMdCq"
   },
   "source": [
    "The baseline logistic regression is useless to Outbrain when clicked can only be explained by ad_id and display_id. It doesn't predict any clicks at all."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "22MlMkoYNCJm"
   },
   "source": [
    "### Code For Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "2wNrzI5-NMfV"
   },
   "outputs": [],
   "source": [
    "#importing modules\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "PZONLgJINSr6"
   },
   "outputs": [],
   "source": [
    "# Preparing the data\n",
    "\n",
    "print (\"Get tables to combine\")\n",
    "content = spark.read.csv(\"/FileStore/tables/promoted_content.csv\", header = True)\n",
    "train = spark.read.csv(\"/FileStore/tables/clicks_train.csv\", header = True)\n",
    "schema = train.printSchema()\n",
    "train = train.selectExpr(\"display_id as display_id\", \"ad_id as ad\", \"clicked as clicked\")\n",
    "\n",
    "# Building the model with iterating over chunks of training data\n",
    "training=True\n",
    "i = 0\n",
    "j = 1\n",
    "while j < 10:\n",
    "  if j < 9:\n",
    "    chunk = train.toPandas()[i:9000000*j]\n",
    "    if i == 0:\n",
    "      i+= 9000000 + 1\n",
    "    else:\n",
    "      i+= 9000000\n",
    "    j+=1\n",
    "  else:\n",
    "    chunk = train.toPandas()[i:6141731]\n",
    "  print('Taking the chunk in to build the model')\n",
    "  chunk.show(5)\n",
    "  joinExpression = chunk[\"ad\"] == content[\"ad_id\"]\n",
    "  # Join type\n",
    "  joinType = \"left\"\n",
    "  # Join command\n",
    "  chunk = chunk.join(content, chunk[\"ad\"] == content[\"ad_id\"], joinType)\n",
    "  # collecting the predictors' names\n",
    "  predictors=[x for x in chunk.columns if x not in ['display_id','clicked', 'ad_id']]\n",
    "  chunk=chunk.fillna(0.0)\n",
    "  chunk = chunk.toPandas()\n",
    "  # building the model\n",
    "  alg = RandomForestClassifier(random_state=1, n_estimators=3, min_samples_split=4, min_samples_leaf=2, warm_start=True)\n",
    "  alg.fit(chunk[predictors], chunk[\"clicked\"])#Fit the Algorithm\n",
    "  print('model fitted on the chunk')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "2WsMnltlOp6c"
   },
   "outputs": [],
   "source": [
    "alg\n",
    "##Out[11]: \n",
    "#RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "#       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
    "#           min_impurity_split=1e-07, min_samples_leaf=2,\n",
    "#           min_samples_split=4, min_weight_fraction_leaf=0.0,\n",
    "#            n_estimators=3, n_jobs=1, oob_score=False, random_state=1,\n",
    "#            verbose=0, warm_start=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Kqo71SG-O3ci"
   },
   "outputs": [],
   "source": [
    "# predicting the clicked likelihood on clicks_test.csv\n",
    "train=''\n",
    "print('Testing')\n",
    "test=spark.read.csv('/FileStore/tables/clicks_test.csv',header=True, inferSchema = \"true\") #Load data\n",
    "test = test.selectExpr(\"display_id as display_id\", \"ad_id as ad\")\n",
    "predY=[]\n",
    "print(\"Merging with content\")\n",
    "joinExpression = test[\"ad\"] == content[\"ad_id\"]\n",
    "# Join type\n",
    "joinType = \"left\"\n",
    "# Join command\n",
    "chunk = test.join(content, joinExpression, joinType)\n",
    "chunk=chunk.fillna(0.0)\n",
    "print(\"predicting\")\n",
    "chunk = chunk.toPandas()\n",
    "#predicting\n",
    "chunk_pred=list(alg.predict_proba(chunk[predictors]).astype(float)[:,1])\n",
    "predY += chunk_pred\n",
    "print(\"done predicting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Iad5J2SwPUCJ"
   },
   "outputs": [],
   "source": [
    "# Preparing the results in submission format for submitting to kaggle\n",
    "## scores with this submission : 0.48569\n",
    "print('Preparing for Submission')\n",
    "filename = \"submission\"\n",
    "test=''#We do not want the iterable version of test\n",
    "test=spark.read.csv('/FileStore/tables/clicks_test.csv',header=True, inferSchema = \"true\") #Load data\n",
    "results=pd.concat((test.toPandas(),pd.DataFrame(predY)) ,axis=1,ignore_index=True)#Combine the predicted values with the ids\n",
    "print(results.head(10))\n",
    "results.rename(\n",
    "  columns={\n",
    "    0 : 'display_id',\n",
    "    1 : 'ad_id',\n",
    "    2 :  'clicked'\n",
    "  },\n",
    "  inplace=True\n",
    ")\n",
    "print(results.head(10))\n",
    "#results=results[results['clicked'] > 0.0]\n",
    "results = results.sort_values(by=['display_id','clicked'], ascending=[True, False])\n",
    "results = results.reset_index(drop=True)\n",
    "results=results[['display_id','ad_id']].groupby('display_id')['ad_id'].agg(lambda col: ' '.join(map(str,col)))\n",
    "print(results.head(5))\n",
    "results=results[['display_id','ad_id']]\n",
    "print(results.head(5))\n",
    "print(\"creating csv\")\n",
    "results.to_csv('/dbfs/FileStore/tables/predict.csv', sep=',', header=True, index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "NbA513P-JCwg"
   },
   "outputs": [],
   "source": [
    "## Local evaluating the model by splitting the training data into two sets\n",
    "print (\"Get tables to combine\")\n",
    "train = spark.read.csv(\"/FileStore/tables/clicks_train.csv\", header = True)\n",
    "schema = train.printSchema()\n",
    "\n",
    "training, testing = train.randomSplit([0.7, 0.3], seed=2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "onFTlBXBJIee"
   },
   "outputs": [],
   "source": [
    "# training model on set of train data\n",
    "i = 0\n",
    "j = 1\n",
    "while j <  7:\n",
    "  if j <= 6:\n",
    "    chunk = training.toPandas()[i:9000000*j]\n",
    "    if i == 0:\n",
    "      i+= 9000000 + 1\n",
    "    else:\n",
    "      i+= 9000000\n",
    "    j+=1\n",
    "  else:\n",
    "    chunk = training.toPandas()[i:6998916]\n",
    "  print('Taking the chunk in to build the model')\n",
    "  print(chunk.head(5))\n",
    "  chunk=pd.merge(chunk,content.toPandas(),how='left',on='ad_id')\n",
    "  predictors=[x for x in chunk.columns if x not in ['display_id','clicked', 'ad_id']]\n",
    "  chunk=chunk.fillna(0.0)\n",
    "  alg_evaluating = RandomForestClassifier(random_state=1, n_estimators=3, min_samples_split=4, min_samples_leaf=2, warm_start=True)\n",
    "  alg_evaluating.fit(chunk[predictors], chunk[\"clicked\"])#Fit the Algorithm\n",
    "  print('model fitted on the chunk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "EKclABohJMux"
   },
   "outputs": [],
   "source": [
    "alg_evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "SN_l49XHJOxo"
   },
   "outputs": [],
   "source": [
    "train=''\n",
    "print('Predicting on training set')\n",
    "testing.printSchema()\n",
    "train_predY=[]\n",
    "print(\"Merging with content\")\n",
    "joinExpression = testing[\"ad\"] == content[\"ad_id\"]\n",
    "# Join type\n",
    "joinType = \"left\"\n",
    "# Join command\n",
    "chunk = testing.join(content, joinExpression, joinType)\n",
    "chunk=chunk.fillna(0.0)\n",
    "print(\"predicting\")\n",
    "chunk = chunk.toPandas()\n",
    "chunk_pred_train=list(alg_evaluating.predict_proba(chunk[predictors]).astype(int)[:,1])\n",
    "train_predY += chunk_pred_train\n",
    "print(\"done predicting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "uV-jbSOSJRBV"
   },
   "outputs": [],
   "source": [
    "#Evaluating\n",
    "print(testing.head(5))\n",
    "trainResults=pd.concat((testing.toPandas(),pd.DataFrame(train_predY)) ,axis=1,ignore_index=True)#Combine the predicted values with the ids\n",
    "print(trainResults.head(5))\n",
    "trainResults.rename(\n",
    "  columns={\n",
    "    0 : 'display_id',\n",
    "    1 : 'ad_id',\n",
    "    2 : 'actual',\n",
    "    3 : 'predicted'\n",
    "  },\n",
    "  inplace=True\n",
    ")\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "jAf7I__8JTml"
   },
   "outputs": [],
   "source": [
    "#confusion matrix\n",
    "print(pd.crosstab(trainResults['actual'], trainResults['predicted'], rownames=['Actual'], colnames=['Predicted']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xkK6MZK5QW0z"
   },
   "source": [
    "###Code for Random Forest using python pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Er0pIMUkQrbg"
   },
   "outputs": [],
   "source": [
    "#importing modules\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "-jzQmuKmRQTX"
   },
   "outputs": [],
   "source": [
    "testing=False\n",
    "filename = 'submission'\n",
    "print (\"combine the data\")\n",
    "content = pd.read_csv('promoted_content.csv')\n",
    "print('Done combining')\n",
    "\n",
    "chunksize=50000# Out of 87141731.\n",
    "train = pd.read_csv('clicks_train.csv',iterator=True,chunksize=chunksize) #Load data\n",
    "print( 'Training')\n",
    "for chunk in train:\n",
    "    print('Taking the chunk in for modeling')\n",
    "    chunk=pd.merge(chunk,content,how='left',on='ad_id')\t\n",
    "    predictors=[x for x in chunk.columns if x not in ['display_id','clicked']]\n",
    "    chunk=chunk.fillna(0.0)\n",
    "    alg = RandomForestClassifier(random_state=1, n_estimators=3, min_samples_split=4, min_samples_leaf=2, warm_start=True)\n",
    "    alg.fit(chunk[predictors], chunk[\"clicked\"])#Fit the Algorithm\n",
    "    print(\"Model built with the chunk\")\n",
    "    if testing:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Xnj3gqxbCEIf"
   },
   "outputs": [],
   "source": [
    "train=''\n",
    "print('Testing')\n",
    "test= pd.read_csv('clicks_test.csv',iterator=True,chunksize=chunksize) #Load data\n",
    "predY=[]\n",
    "for chunk in test:\n",
    "    init_chunk_size=len(chunk)\n",
    "    chunk=pd.merge(chunk,content,how='left',on='ad_id')\n",
    "    chunk=chunk.fillna(0.0)\n",
    "    chunk_pred=list(alg.predict_proba(chunk[predictors]).astype(float)[:,1])\n",
    "    predY += chunk_pred\n",
    "    print(\"Prediction done for chunk\")\n",
    "    if testing:\n",
    "        break\n",
    "print('Done Testing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "TyB-Nh7yCJfA"
   },
   "outputs": [],
   "source": [
    "print('Preparing results Submission')\n",
    "test=''\n",
    "test= pd.read_csv('clicks_test.csv')#But rather the full version\n",
    "results=pd.concat((test,pd.DataFrame(predY)) ,axis=1,ignore_index=True)#Combine the predicted values with the ids\n",
    "print(results.head(10))\n",
    "#Renaming the columns\n",
    "results.columns = ['display_id','ad_id','clicked']\n",
    "results = results.sort_values(by=['display_id','clicked'], ascending=[True, False])\n",
    "results = results.reset_index(drop=True)\n",
    "results=results[['display_id','ad_id']].groupby('display_id')['ad_id'].agg(lambda col: ' '.join(map(str,col)))\n",
    "results.columns=[['display_id','ad_id']]\n",
    "print(\"creating csv\")\n",
    "results.to_csv(filename+'.csv')\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AOxk2c4fY0AQ"
   },
   "source": [
    "## Method parameter settings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T6SW1zgaY0Ad"
   },
   "source": [
    "1. Simple Aggregation: This model is based on simple aggregation and it uses 'ad_id', 'clicked' and 'display_id'.\n",
    "2. Logistic Regression: The best performing model uses PySpark's default parameters of the 'LogisticRegression' algorithm. It uses the columns 'ad_id', 'platform', 'geo_location', and a interaction term between 'ad_id' and \"geo_location\". Since some of the ads are probably location related an interaction between these two variables. The rest was simply chosen because its results were the best.\n",
    "3. Cost Sensitive Model: The best performing model uses a cost matrix that gives a false negative a cost of 3 and a false positive a cost of 1. True positive and negative are assigned zero cost. These cost values were simply chosen because they performed best.\n",
    "4. Random Forest Classification: The best performing model uses random_state=1, n_estimators=3, min_samples_split=4, min_samples_leaf=2, warm_start=True, as the parameter. These parameters were chosen because of there best performance.\n",
    "The model also uses 'display_id', 'ad_id', 'document_id', 'campaign_id', and 'advertiser_id\" as the independent variables because a individual that comes to a website are motivated by only some specific content and for that reason using promoted_content data in cohesion with training helps predict the likelihood of the clicks based on the content they are shown. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_OsUsppLYyXL"
   },
   "source": [
    "## Data Mining performance metrics and the evaluation approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e090sxjUYyXp"
   },
   "source": [
    "1. Simple Aggregation: Model is evaluated by Kaggle, the public score for the approach is 0.63713.\n",
    "2. Logistic Regression: To evaluate the model we chose a train-test split (0.7/0.3) meaning that we trained the model on 70% of the data and then evaluated the performance on the remaining 30%. The performance measures of our choice are precision, recall, and F-measure for both the positive and negative class. The metrics for the positive class shows how well the model does in predicting a click. Besides the measures for each class, we also were interested in the models overall performance - it's accuracy. \n",
    "The applied performance measures are standard for classification tasks to raise awareness of possible risks associated with the application of the model.\n",
    "We tested other methods such as support vector machine model using a linear kernel or a gradiens boosting tree model. However, these methods performed slightly worse than the logistic regression in the base model. Due to time constraints, we decided to only fine-tune the logistic regression model. We hoped for a F-score of 0.5 and a recall of 0.3 but maybe low precision due to the size of the data set.\n",
    "3. Random Forest Classification: The model was evaluated by Kaggle, the best public score is 0.53601. We also split the training data set into two sets, to evaluate the model, the  precision(no) = 0.806388 and recall(no) = 0.99995\n",
    "4. Cost Sensitive Model: To evaluate the cost sensitive model we used a 10-fold cross-validation to receive the standard performance measures for classification - recall, precision, and F-score. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OU7QwrT6fM76"
   },
   "source": [
    "#**Implementation Effort and Risk Management**\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## Project Timeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oRkWeJ5GfM8Q"
   },
   "source": [
    "We originally estimated about 38 hours for the project as a whole. However, we spent already at least 80 hours by the time of the interim report. At the end of the project we spent about 100 hours which is more than 2.5 times as much as we anticipated. \n",
    "We didn't know about the amount of time we'd spend waiting for the code to run before we started the project. Our computers aren't super computers and thus working with large amounts of data requires a lot of time.\n",
    "\n",
    "For future real-world projects we recommend to consider about 100 hours, a very poweful computer, and subscription to a cloud IDE supporting PySpark. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9gusGuc_f5ln"
   },
   "source": [
    "## Risks and Challenges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dQ0cQhtkf5l6"
   },
   "source": [
    "The major risk involved in any data project is that a bad model would result in many of the business questions unanswered. Given the huge dataset we had to find the right and most importantly best answer to our question. \n",
    "Another challenge for any BIG data project is performing an analysis on a big dataset. As mentioned earlier, most computers aren't suited for this kind of task and we were really surprised by the amount of time we spent on running the code.\n",
    "One risk that any team is facing is the risk of everyone contributing. We had delegated tasks to each of the team member and all of us but one worked parallely on different analytical approaches. Robert did not communicate with us and didn't reply to any of our attempts to contact him. This was very unfortunate since the four of us had to juggle even more work than anticipated. \n",
    "\n",
    "To avoid these risks and challenges in the future we recommend to frequently perform validations on the model to make sure that the team is on the right track. To receive accurate results it is also important to use proper data preparation techniques. The challenge of big data can be solved by reducing the data at the beginning and only applying the final model on the whole data or by using a cloud IDE.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "xB00DNRrjska",
    "-HEGmrhV-fyb",
    "22MlMkoYNCJm",
    "xkK6MZK5QW0z"
   ],
   "default_view": {},
   "name": "FINAL_REPORT.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
